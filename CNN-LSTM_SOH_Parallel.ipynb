{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SOH_func_scaler import *\n",
    "import matplotlib.pyplot as pl\n",
    "from keras import models, layers\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'Scaler_Norm'\n",
    "\n",
    "FILE_00 = 'data_csv/CYCLE_CSV_data00.csv'\n",
    "FILE_01 = 'data_csv/CYCLE_CSV_data01.csv'\n",
    "FILE_02 = 'data_csv/CYCLE_CSV_data02.csv'\n",
    "FILE_03 = 'data_csv/CYCLE_CSV_data03.csv'\n",
    "FILE_04 = 'data_csv/CYCLE_CSV_data04.csv'\n",
    "FILE_05 = 'data_csv/CYCLE_CSV_data05.csv'\n",
    "FILE_06 = 'data_csv/CYCLE_CSV_data06.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_labels_x = ['인덱스', '사이클_번호', '누적_용량(Ah)', '누적_에너지(Wh)', '쿨롱_효율(%)', '에너지_효율(%)', '최대_전압(V)', '충전_최종전압(V)', '단위_충전_용량(Ah/g)', '방전_최종전압(V)', '단위_방전_용량(Ah/g)']\n",
    "drop_labels_y = ['인덱스', '사이클_번호', '충전_용량(Ah)', '누적_용량(Ah)', '충전_에너지(Wh)', '방전_에너지(Wh)', '누적_에너지(Wh)', '쿨롱_효율(%)', '에너지_효율(%)', '최대_전압(V)', '충전_최종전압(V)', '방전_최종전압(V)', '단위_충전_용량(Ah/g)', '방전_최종전압(V)', '단위_방전_용량(Ah/g)']\n",
    "\n",
    "param = {'seq_len' : 20, 'num_units' : 32, 'num_filters' : 256, 'window' : 3, 'dropout': 0.2, 'num_epochs' : 5000, 'num_dense': 16}\n",
    "\n",
    "log_dir = f\"logs/{VERSION}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\") + f'-{param[\"num_filters\"]}FL-{param[\"num_units\"]}UN-{param[\"num_epochs\"]}EP-{param[\"seq_len\"]}SQ'\n",
    "file_path = f'Checkpoints\\{VERSION}\\SOH_Checkpoint\\{param[\"num_filters\"]}FL-{param[\"num_units\"]}UN-{param[\"num_epochs\"]}EP-{param[\"seq_len\"]}SQ\\{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.h5'\n",
    "hist_freq = 250\n",
    "\n",
    "save_path = f'outputs\\{VERSION}\\{param[\"num_filters\"]}FL-{param[\"num_units\"]}UN-{param[\"num_epochs\"]}EP-{param[\"seq_len\"]}SQ'\n",
    "try:\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "except OSError:\n",
    "    print('Error Creating Directory...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data00, data_cap00 = get_data(FILE_00, drop_labels_x, drop_labels_y)\n",
    "data01, data_cap01 = get_data(FILE_01, drop_labels_x, drop_labels_y)\n",
    "data02, data_cap02 = get_data(FILE_02, drop_labels_x, drop_labels_y)\n",
    "data04, data_cap04 = get_data(FILE_04, drop_labels_x, drop_labels_y)\n",
    "data_test, data_cap_test = get_data(FILE_05, drop_labels_x, drop_labels_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train00 = seq_gen_x(data00, param['seq_len'])\n",
    "y_train00 = seq_gen_y(data_cap00, param['seq_len'])\n",
    "x_train01 = seq_gen_x(data01, param['seq_len'])\n",
    "y_train01 = seq_gen_y(data_cap01, param['seq_len'])\n",
    "x_train02 = seq_gen_x(data02, param['seq_len'])\n",
    "y_train02 = seq_gen_y(data_cap02, param['seq_len'])\n",
    "x_train04 = seq_gen_x(data04, param['seq_len'])\n",
    "y_train04 = seq_gen_y(data_cap04, param['seq_len'])\n",
    "x_test = seq_gen_x(data_test, param['seq_len'])\n",
    "y_test = seq_gen_y(data_cap_test, param['seq_len'])\n",
    "print(x_train00.shape)\n",
    "print(y_train00.shape)\n",
    "print(x_train00[0, 0:6, 1])\n",
    "print(y_train00[0, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None, x_train00.shape[-1]), name = 'Inputs')\n",
    "x1 = layers.Conv1D(param['num_filters'], param['window'], padding='causal')(inputs)\n",
    "x2 = layers.LSTM(param['num_units'], return_sequences = True)(inputs)\n",
    "x = tf.concat(x1, x2)\n",
    "x = layers.TimeDistributed(layers.Dense(param['num_dense']))(x)\n",
    "outputs = layers.TimeDistributed(layers.Dense(1))(x)\n",
    "model = models.Model(inputs = inputs, outputs = outputs, name = 'CNN_LSTM_PARALLEL')\n",
    "model.compile(loss = 'mse', optimizer = 'Adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "callback_list = [ModelCheckpoint(filepath = file_path, monitor = 'val_loss', save_best_only = True),\n",
    "                 TensorBoard(log_dir=log_dir, histogram_freq=hist_freq)]\n",
    "fitdata = model.fit(x_train00, y_train00, epochs=param['num_epochs'], verbose = 1, batch_size=BATCH_SIZE, validation_split = 0.3, callbacks=callback_list)\n",
    "callback_list = [ModelCheckpoint(filepath = file_path, monitor = 'val_loss', save_best_only = True),\n",
    "                 TensorBoard(log_dir=log_dir, histogram_freq=hist_freq)]\n",
    "fitdata = model.fit(x_train01, y_train01, epochs=param['num_epochs'], verbose = 1, batch_size=BATCH_SIZE, validation_split = 0.3, callbacks=callback_list)\n",
    "callback_list = [ModelCheckpoint(filepath = file_path, monitor = 'val_loss', save_best_only = True),\n",
    "                 TensorBoard(log_dir=log_dir, histogram_freq=hist_freq)]\n",
    "fitdata = model.fit(x_train02, y_train02, epochs=param['num_epochs'], verbose = 1, batch_size=BATCH_SIZE, validation_split = 0.3, callbacks=callback_list)\n",
    "callback_list = [ModelCheckpoint(filepath = file_path, monitor = 'val_loss', save_best_only = True),\n",
    "                 TensorBoard(log_dir=log_dir, histogram_freq=hist_freq)]\n",
    "fitdata = model.fit(x_train04, y_train04, epochs=param['num_epochs'], verbose = 1, batch_size=BATCH_SIZE, validation_split = 0.3, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE, MAE, Error_rate = show_and_prove(model, file_path, x_test, y_test, save_path, return_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(dpi=150)\n",
    "line = pl.plot(Error_rate)\n",
    "pl.ylim(-10, 10)\n",
    "pl.ylabel('SOH Error (%)')\n",
    "pl.xlabel('Cycles')\n",
    "pl.setp(line, color='b', linewidth=0.5)\n",
    "pl.savefig(f'{save_path}\\\\ErrRate-RMSE({RMSE:.4f})MAE({MAE:.4f}).png')\n",
    "pl.show()\n",
    "print(f'RMSE({RMSE:.6f}), MAE({MAE:.6f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b776e8a1ce9412d9556c02947d53a9e8ae7bbb4e7b1b579f7ffbe853627ce066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
